{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch"],"metadata":{"id":"NnHqhFrUQNQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKII1YvjP1S9"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from sklearn.metrics import f1_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"],"metadata":{"id":"l7r1Zf-sju5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Custom Dataset\n","custom_dataset = ImageFolder(root='path/to/dataset', transform=transform)\n","\n","train_size = int(0.8 * len(custom_dataset))\n","val_size = len(custom_dataset) - train_size\n","\n","train_dataset, val_dataset = torch.utils.data.random_split(custom_dataset, [train_size, val_size])\n","\n","trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"yrnWgpoWUCL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n","                                          shuffle=True, num_workers=2)\n","\n","val_dataset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive', train=False,\n","                                       download=True, transform=transform)\n","valloader = torch.utils.data.DataLoader(val_dataset, batch_size=64,\n","                                         shuffle=False, num_workers=2)"],"metadata":{"id":"jlxmO8l4dkbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage import data, io\n","myit = iter(trainloader)\n","print(next(myit)[0][0].size())\n","io.imshow(next(myit)[0][0].permute(1,2,0).numpy())"],"metadata":{"id":"FseILHgNbnNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG16(nn.Module):\n","    def __init__(self):\n","        super(VGG16, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(256, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding='same'),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((7,7))\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 10) # 10 classes\n","        )\n","\n","    def forward(self, x):\n","      x = self.features(x)\n","      x = self.avgpool(x)\n","      x = torch.flatten(x, 1)\n","      x = self.classifier(x)\n","\n","      return x"],"metadata":{"id":"trzV5kABQZkm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","model = VGG16()\n","model.to(device)\n","summary(model, (3, 32, 32))"],"metadata":{"id":"EXrdyUumayEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vgg16 = VGG16().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.001)"],"metadata":{"id":"-idKESS8UCtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses = []\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","  running_loss = 0.0\n","\n","  for i, data in enumerate(trainloader, 0):\n","    inputs, labels = data[0].to(device), data[1].to(device)\n","\n","    optimizer.zero_grad()\n","\n","    outputs = vgg16(inputs) #vgg16\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","\n","    if i % 100 == 99:\n","      print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n","      f\"Step [{i + 1}/{len(trainloader)}], \"\n","      f\"Loss: {running_loss / 100:.4f}\")\n","\n","      train_losses.append(running_loss / 100)\n","      running_loss = 0.0\n","\n","print(\"Finished Training!\")"],"metadata":{"id":"pFc4nh_MUd-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg16.eval()\n","val_loss = 0.0\n","val_predictions = []\n","val_targets = []\n","\n","with torch.no_grad():\n","  for data in valloader:\n","    inputs, labels = data[0].to(device), data[1].to(device)\n","    outputs = vgg16(inputs)\n","    loss = criterion(outputs, labels)\n","    val_loss += loss.item()\n","\n","    _, predicted = torch.max(outputs, 1)\n","    val_predictions.extend(predicted.cpu().numpy())\n","    val_targets.extend(labels.cpu().numpy())\n","\n","val_loss /= len(valloader)\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(train_losses, label='Training Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training Loss over Epochs')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"dMjaO0cMVuw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in valloader:\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        outputs = vgg16(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Accuracy on the validation set: {accuracy:.2f}%')"],"metadata":{"id":"5KFSCkT0elgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1 = f1_score(val_targets, val_predictions, average='macro')\n","print(f\"F1 Score: {f1:.4f}\")"],"metadata":{"id":"2ZNcWPnTc8dW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(val_targets, val_predictions)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"],"metadata":{"id":"WrRnCGjtdGvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(val_predictions, val_targets)\n","plt.figure(figsize=(8,6))\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix')\n","plt.colorbar()\n","classes = ['your', 'dataset', 'classes']\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes, rotation=45)\n","plt.yticks(tick_marks, classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"-ClJV7bXdOT_"},"execution_count":null,"outputs":[]}]}